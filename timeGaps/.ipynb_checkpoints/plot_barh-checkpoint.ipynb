{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.rc('legend', fontsize=20) # using a size in points\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.facecolor'] = \"w\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load opsim database\n",
    "dbpath = \"/home/idies/workspace/lsst_cadence/FBS_1.5/\"  # path to all opsim databases\n",
    "\n",
    "# output directory\n",
    "outDir = '/home/idies/workspace/Temporary/lixl/scratch/outDir'\n",
    "#resultsDb = db.ResultsDb(outDir=outDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name of all opsim dbs\n",
    "workpath = os.getcwd()\n",
    "os.chdir(dbpath)  # change to opsim database directory\n",
    "dblist_all = glob.glob('*.db') \n",
    "#workpath = '/home/idies/workspace/Storage/lixl/persistent/LSST_OpSim/unknowns/timeGaps/'\n",
    "os.chdir(workpath) # change back to work directory\n",
    "dblist_all.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_v1.5_10yrs.db']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dblist_all[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMC_SMC_coverage.ipynb\r\n",
      "dT_skymap.ipynb\r\n",
      "dT_skymap_all.ipynb\r\n",
      "\u001b[0m\u001b[01;34mdata\u001b[0m/\r\n",
      "depth_wfd_ms.ipynb\r\n",
      "df_Nfields_LMC_inwfd.csv\r\n",
      "df_Nfields_allsky.csv\r\n",
      "df_Nfields_footprint_big_wfdv1.5_10yrs.db.csv\r\n",
      "df_Nfields_wfd.csv\r\n",
      "df_Nfields_wfd_v1.5.csv\r\n",
      "df_Nstar_LMC_inwfd.csv\r\n",
      "df_Nstar_allsky.csv\r\n",
      "df_Nstar_wfd.csv\r\n",
      "df_Nstars_footprint_big_wfdv1.5_10yrs.db.csv\r\n",
      "df_Nstars_wfd_v1.5.csv\r\n",
      "df_rank_t.csv\r\n",
      "df_tgapsFoM_LMC_inwfd.csv\r\n",
      "df_tgapsFoM_footprint_big_wfdv1.5_10yrs.db.csv\r\n",
      "df_tgapsFoM_wfd_v1.5.csv\r\n",
      "\u001b[01;34mfigures\u001b[0m/\r\n",
      "filterPairTGapsMetric.ipynb\r\n",
      "footprintFoM.ipynb\r\n",
      "\u001b[01;34mhistory\u001b[0m/\r\n",
      "minisurvey_footprint.ipynb\r\n",
      "normalize.ipynb\r\n",
      "plot_barh.ipynb\r\n",
      "plot_barh_allsky.ipynb\r\n",
      "plot_barh_minisurvey_allsky.ipynb\r\n",
      "plot_barh_minisurvey_inwfd.ipynb\r\n",
      "plot_barh_wfd.ipynb\r\n",
      "plot_fig34.ipynb\r\n",
      "plot_footprint.ipynb\r\n",
      "plot_opsim_footprint.ipynb\r\n",
      "plot_parallel_compare.ipynb\r\n",
      "plot_radar_parallel.ipynb\r\n",
      "starDens16.npz\r\n",
      "star_density_map.ipynb\r\n",
      "star_density_map_fromWill.ipynb\r\n",
      "tgaps_minisurvey-GP.ipynb\r\n",
      "tgaps_minisurvey.ipynb\r\n",
      "tgaps_wfd_noddf.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "cols_all = ['uu', 'ug', 'ur', 'ui', 'uz', 'uy', 'gg', 'gr', 'gi', 'gz', 'gy', 'rr', 'ri', 'rz', 'ry', 'ii', 'iz', 'iy', 'zz', 'zy', 'yy']\n",
    "\n",
    "cols_same = [ 'uu',  'gg',  'rr',  'ii',  'zz',  'yy']\n",
    "\n",
    "cols_diff = ['ug', 'ur', 'ui', 'uz', 'uy', 'gr', 'gi', 'gz', 'gy', 'ri', 'rz', 'ry', 'iz', 'iy', 'zy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_norm(df=[], cols=['u'], fomcsv = 'df_tgapsFoM_GP.csv'):\n",
    "    \"\"\"return normalized dataframe\n",
    "    cols: columns to normalize\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(df)!=0:\n",
    "        df_fom = df.copy()\n",
    "    else:\n",
    "        df_fom = pd.read_csv(fomcsv)\n",
    "    \n",
    "    if 'db' not in df_fom.columns:\n",
    "        df_fom['db'] = dblist_all\n",
    "        \n",
    "    # scale fom table to 0 and 1\n",
    "    df_new = df_fom[ ['db', 'prop'] ].copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        # df_new[ col ] = np.tanh ( scale ( df_fom[col] ) * 3 )\n",
    "        df_new[col] = scale(df_fom[col]) \n",
    "        \n",
    "    df_new['db'] = df_new['db'].apply(lambda x: x.replace(\"_v1.5_10yrs.db\", \"\") )\n",
    "    df_new['db'] = df_new['db'].apply(lambda x: x.replace(\"v1.5_10yrs.db\", \"\") )\n",
    "    \n",
    "    df_new['family'] = df_new.apply(get_family, axis=1)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def scale(arr, mode=0):\n",
    "    \"\"\"scale array by max\"\"\"\n",
    "    newarr = arr / arr.max()\n",
    "    if mode==1:\n",
    "        newarr = (arr - arr.min()) / (arr.max()-arr.min())\n",
    "    return newarr\n",
    "\n",
    "def get_family(df):\n",
    "    \"\"\"get family of opsim\"\"\"\n",
    "    \n",
    "    return df['db'].split('_')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barh(df_new, colon, byfamily=True, savefig=None, figsize=(8, 30), facecolor=\"#f1f1f3\", title='', **kwargs):\n",
    "    \"\"\"barh plot of FoM\"\"\"\n",
    "\n",
    "    df_ = df_new.copy()\n",
    "    df_['total'] = np.sum(df_[ colon ], axis=1)\n",
    "    \n",
    "    # get the max FOM of each family and sort by this\n",
    "    df_mean_family = df_.groupby(by = \"family\", as_index=False).max()[['family', 'total']]\n",
    "    df_ = df_.merge(df_mean_family, on='family', how='left', suffixes=['', '_fmean'],)\n",
    "    \n",
    "    df_ = df_.set_index('db')\n",
    "    if byfamily:\n",
    "        df_ = df_.sort_values(by=['total_fmean', 'total'], ascending=[True, True])\n",
    "    else:\n",
    "        # sort by total only\n",
    "        df_ = df_.sort_values(by='total', ascending=True)\n",
    "    \n",
    "    df_[colon] = df_[colon]/len(colon)\n",
    "    ax = df_[ colon ].plot.barh(stacked=True, figsize=figsize, **kwargs)\n",
    "    \n",
    "    # get positions of hlines\n",
    "    if byfamily:\n",
    "        hlines = df_.groupby(by='family', as_index=False, sort=False).count().cumsum()['total_fmean'].values - 0.5\n",
    "        hlines = [hlines, hlines]\n",
    "        ax.plot((-0.5, 1), hlines, 'k-', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('normalized score', fontsize=20)\n",
    "    plt.ylabel('')\n",
    "    plt.legend(loc='lower right', frameon=True)\n",
    "    plt.xlim([0,1.01])\n",
    "    \n",
    "    #ax = plt.gca()\n",
    "    ax.set_facecolor(facecolor)\n",
    "    ax.set_title(title)\n",
    "    if savefig!=None:\n",
    "        plt.savefig(savefig, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def get_mycmap(pairs='diff'):\n",
    "    \"\"\"discrete colormap for filter pairs\"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.colors as mcolors\n",
    "    \n",
    "    # colors in total\n",
    "    # combine them and build a new colormap\n",
    "\n",
    "    thecbases = [plt.cm.Blues,\n",
    "                 plt.cm.Greens,\n",
    "                 plt.cm.Purples,\n",
    "                 plt.cm.Reds,\n",
    "                 plt.cm.YlOrBr,\n",
    "                 (240./255,230./255,140./255, 1.),\n",
    "                ]\n",
    "\n",
    "    grad = [thecbases[i](np.linspace(0, 1, 8-i)[::-1][1:]) for i in range(5)]\n",
    "    \n",
    "    #thecmaps = {'diff': , [thecbases[i](np.linspace(0, 1, 8-i)[::-1][1:]) for i in range(5)]\n",
    "    #                'same':[thecbases[i](np.linspace(0, 1, 7-i)[-3 if i < 2 else -2]) \n",
    "    #                     for i in range(5)] + [thecbases[5]]}\n",
    "    \n",
    "    thecmaps = {'diff': [ grad[i] [ 1:6 - i ] for i in range(5) ] ,\n",
    "                'same':[ grad[i] [ 1 if i!=5 else 0 ] for i in range(5) ] + [thecbases[5]]}\n",
    "    \n",
    "    colors = np.vstack( [c for c in thecmaps[pairs]] )\n",
    "    mymap = mcolors.LinearSegmentedColormap.from_list('my_colormap', colors)\n",
    "            \n",
    "    #plt.pcolor(data, cmap=mymap)\n",
    "    #plt.colorbar()\n",
    "    #plt.show()\n",
    "    return mymap\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
