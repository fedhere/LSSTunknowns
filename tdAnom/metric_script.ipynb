{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python script for time gaps metrics\n",
    "\n",
    "- filterPairTGapsMetric\n",
    "- filterPairTGapsFootprintMetric\n",
    "- depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filterPairTGapsMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "import lsst.sims.maf.db as db\n",
    "from lsst.sims.maf.utils import m52snr\n",
    "\n",
    "def RADec2pix(nside, ra, dec, degree=True):\n",
    "    \"\"\"\n",
    "    Calculate the nearest healpixel ID of an RA/Dec array, assuming nside.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nside : int\n",
    "        The nside value of the healpix grid.\n",
    "    ra : numpy.ndarray\n",
    "        The RA values to be converted to healpix ids, in degree by default.\n",
    "    dec : numpy.ndarray\n",
    "        The Dec values to be converted to healpix ids, in degree by default.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The healpix ids.\n",
    "    \"\"\"\n",
    "    if degree:\n",
    "        ra = np.radians(ra) # change to radians\n",
    "        dec = np.radians(dec)\n",
    "    \n",
    "    lat = np.pi/2. - dec\n",
    "    hpid = hp.ang2pix(nside, lat, ra )\n",
    "    return hpid\n",
    "\n",
    "class filterPairTGapsMetric(metrics.BaseMetric):\n",
    "    \"\"\"\n",
    "    Count the number of filter pairs within tmin~tmax\n",
    "    \n",
    "    returns\n",
    "    dT or N_v * np.exp(-Dkl) for each fields\n",
    "    \n",
    "    Parameters:\n",
    "        colname: \n",
    "        fltpair: filter pair, eg ['r', 'i']\n",
    "        snr_lim: list, signal to noise ratio (fiveSigmaDepth) threshold for fltpair, default [5, 5]\n",
    "        filename: output a csv table for time gaps of each field\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, colname=['observationStartMJD', 'filter', 'fiveSigmaDepth'], \n",
    "                 fltpair=['r', 'i'], tmin=0, tmax=1.5/24, bins=50, mag_lim=[18, 18],\n",
    "                 save_dT=False, filename=None, dataout=True, **kwargs):\n",
    "        self.colname = colname\n",
    "        self.filename = filename\n",
    "        self.fltpair = fltpair\n",
    "        self.mag_lim = mag_lim\n",
    "        self.dataout = dataout\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.bins = bins\n",
    "        self.save_dT = save_dT\n",
    "        \n",
    "        self.Nrun = 0   # record the how many time run run()\n",
    "        if filename!=None:\n",
    "            if os.path.isfile(filename):\n",
    "                # rm old file\n",
    "                os.system(\"rm {}\".format(filename))\n",
    "                \n",
    "        if self.dataout:\n",
    "            super().__init__(col=self.colname, metricDtype='object', **kwargs)\n",
    "        else:\n",
    "            super().__init__(col=self.colname, metricDtype='float', **kwargs)\n",
    "    \n",
    "    def save_to_file(self, dic, filename=\"test_pkl.pkl\"):\n",
    "        '''save dict item to pickle file'''\n",
    "        \n",
    "        #df = self.load_from_pkl(filename)\n",
    "\n",
    "        #df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "\n",
    "        #df.to_pickle(filename)\n",
    "        df = pd.DataFrame(dic)\n",
    "        with open(filename, 'a') as f:\n",
    "            df.to_csv(f, header=f.tell()==0, index=None)\n",
    "    \n",
    "    def get_Dkl_i(self, values):\n",
    "        '''kl divergence for histogram'''\n",
    "        if values.any():\n",
    "            values = values + 0.00001  # make each element non-zero\n",
    "            prob = (values) / values.sum()  \n",
    "        \n",
    "            prob_uni = np.ones( len(prob) ) / len(prob)\n",
    "            return np.sum( prob_uni * np.log(prob_uni / prob) )\n",
    "        \n",
    "        else:\n",
    "            return np.NaN\n",
    "        \n",
    "    def get_FoM_i(self, dT_all, tmin=0, tmax=1.5/24, bins=50):\n",
    "        \"\"\"return FoM from array of metricValues\"\"\"\n",
    "                \n",
    "        dT_tlim = dT_all[(dT_all>tmin)&(dT_all<tmax)] \n",
    "        Nv = len(dT_tlim)\n",
    "    \n",
    "        values, bins_ = np.histogram(dT_tlim, bins=bins);\n",
    "    \n",
    "        Dkl = self.get_Dkl_i(values)\n",
    "    \n",
    "        FoM_i = Nv * np.exp(-Dkl)\n",
    "        \n",
    "        #print(self.Nrun, len(dT_all), Nv, Dkl, FoM_i)\n",
    "        return Nv, Dkl, FoM_i, dT_tlim\n",
    "      \n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        \n",
    "        # return all possible time gaps for each fields\n",
    "        \n",
    "        f0 = self.fltpair[0]\n",
    "        f1 = self.fltpair[1]\n",
    "        \n",
    "        #check input config\n",
    "        #print(f0, f1, self.tmin, self.tmax, self.mag_lim)\n",
    "            \n",
    "        # sort dataSlice\n",
    "        \n",
    "        idx0 = ( dataSlice['filter'] == f0 ) & ( dataSlice['fiveSigmaDepth'] > self.mag_lim[0])\n",
    "        idx1 = ( dataSlice['filter'] == f1 ) & ( dataSlice['fiveSigmaDepth'] > self.mag_lim[1])\n",
    "        \n",
    "        timeCol0 = dataSlice['observationStartMJD'][idx0]\n",
    "        timeCol1 = dataSlice['observationStartMJD'][idx1]\n",
    "\n",
    "        timeCol0 = timeCol0.reshape((len(timeCol0), 1))\n",
    "        timeCol1 = timeCol1.reshape((len(timeCol1), 1))\n",
    "        \n",
    "        # calculate time gaps matrix\n",
    "        diffmat = np.abs( np.subtract(timeCol0, timeCol1.T) ) \n",
    "        \n",
    "        # collect all time gaps\n",
    "        if f0==f1:\n",
    "            # get only triangle part\n",
    "            dt_tri = np.tril(diffmat, -1)\n",
    "            dT = dt_tri[dt_tri!=0]    # flatten lower triangle \n",
    "        else:\n",
    "            dT = diffmat.flatten()\n",
    "\n",
    "        Nv, Dkl, FoM_i, dT_tlim = self.get_FoM_i(dT, tmin=self.tmin, tmax=self.tmax, bins=self.bins)\n",
    "        \n",
    "        # print(self.Nrun, np.min(dataSlice['fiveSigmaDepth'][idx0]), np.min(dataSlice['fiveSigmaDepth'][idx1]),)\n",
    "        self.Nrun += 1\n",
    "        # write results to csv file\n",
    "        fieldRA = np.mean(dataSlice['fieldRA']) ,\n",
    "        fieldDec = np.mean(dataSlice['fieldDec']),\n",
    "        \n",
    "        if self.save_dT:\n",
    "            dic = {'Nrun': self.Nrun, \n",
    "                'pixId': RADec2pix(nside=16, ra=fieldRA, dec=fieldDec)[0],\n",
    "                'Nv': Nv,\n",
    "                'Dkl': Dkl,\n",
    "                'FoM_i': FoM_i,\n",
    "                'dT_lim': dT_tlim\n",
    "                  }\n",
    "        else:\n",
    "            dic = {'Nrun': self.Nrun, \n",
    "                'pixId': RADec2pix(nside=16, ra=fieldRA, dec=fieldDec)[0],\n",
    "                'Nv': Nv,\n",
    "                'Dkl': Dkl,\n",
    "                'FoM_i': FoM_i,\n",
    "                # 'dT_lim': dT_tlim\n",
    "                  }\n",
    "            \n",
    "        if self.filename!=None:\n",
    "            self.save_to_file(dic, filename=self.filename)\n",
    "        \n",
    "        if self.dataout:\n",
    "            # return dT\n",
    "            result = dic\n",
    "            return result\n",
    "        else:\n",
    "        #    f0 = self.fltpair[0]\n",
    "        #    f1 = self.fltpair[1]\n",
    "            result = np.min(dT) if len(dT)!=0 else np.inf\n",
    "            return float(result) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filterPairTGapsFootprintMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "import lsst.sims.maf.db as db\n",
    "from lsst.sims.maf.utils import m52snr\n",
    "\n",
    "def RADec2pix(nside, ra, dec, degree=True):\n",
    "    \"\"\"\n",
    "    Calculate the nearest healpixel ID of an RA/Dec array, assuming nside.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nside : int\n",
    "        The nside value of the healpix grid.\n",
    "    ra : numpy.ndarray\n",
    "        The RA values to be converted to healpix ids, in degree by default.\n",
    "    dec : numpy.ndarray\n",
    "        The Dec values to be converted to healpix ids, in degree by default.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The healpix ids.\n",
    "    \"\"\"\n",
    "    if degree:\n",
    "        ra = np.radians(ra) # change to radians\n",
    "        dec = np.radians(dec)\n",
    "    \n",
    "    lat = np.pi/2. - dec\n",
    "    hpid = hp.ang2pix(nside, lat, ra )\n",
    "    return hpid\n",
    "\n",
    "# threshold from WFD\n",
    "Nvth = {'uu': 1770.0,\n",
    " 'ug': 50.0,\n",
    " 'ur': 47.0,\n",
    " 'ui': 6.0,\n",
    " 'uz': 0.0,\n",
    " 'uy': 0.0,\n",
    " 'gg': 3828.0,\n",
    " 'gr': 91.0,\n",
    " 'gi': 17.0,\n",
    " 'gz': 0.0,\n",
    " 'gy': 0.0,\n",
    " 'rr': 21384.0,\n",
    " 'ri': 129.0,\n",
    " 'rz': 9.0,\n",
    " 'ry': 1.0,\n",
    " 'ii': 21690.0,\n",
    " 'iz': 149.0,\n",
    " 'iy': 26.0,\n",
    " 'zz': 17310.5,\n",
    " 'zy': 123.0,\n",
    " 'yy': 18998.0}\n",
    "\n",
    "class filterPairTGapsFootprintMetric(metrics.BaseMetric):\n",
    "    \"\"\"\n",
    "    Count the number of filter pairs within tmin~tmax\n",
    "    and check whether a field have number of time gaps larger than threshold \n",
    "    \n",
    "    returns\n",
    "    True if number of time gaps given threshold\n",
    "    \n",
    "    # dT or N_v * np.exp(-Dkl) for each fields\n",
    "    \n",
    "    Parameters:\n",
    "        colname: \n",
    "        fltpair: filter pair, eg ['r', 'i']\n",
    "        snr_lim: list, signal to noise ratio (fiveSigmaDepth) threshold for fltpair, default [5, 5]\n",
    "        filename: output a csv table for time gaps of each field\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, colname=['observationStartMJD', 'filter', 'fiveSigmaDepth'], \n",
    "                 fltpair=['r', 'i'], tmin=0, tmax=1.5/24, bins=50, mag_lim=[18, 18],\n",
    "                 save_dT=False, filename=None, dataout=True, \n",
    "                 Nvth=Nvth,\n",
    "                 **kwargs):\n",
    "        self.colname = colname\n",
    "        self.filename = filename\n",
    "        self.fltpair = fltpair\n",
    "        self.mag_lim = mag_lim\n",
    "        self.dataout = dataout\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.bins = bins\n",
    "        self.save_dT = save_dT\n",
    "        self.Nvth = Nvth\n",
    "        \n",
    "        self.Nrun = 0   # record the how many time run run()\n",
    "        if filename!=None:\n",
    "            if os.path.isfile(filename):\n",
    "                # rm old file\n",
    "                os.system(\"rm {}\".format(filename))\n",
    "                \n",
    "        if self.dataout:\n",
    "            super().__init__(col=self.colname, metricDtype='object', **kwargs)\n",
    "        else:\n",
    "            super().__init__(col=self.colname, metricDtype='float', **kwargs)\n",
    "    \n",
    "    def save_to_file(self, dic, filename=\"test_pkl.pkl\"):\n",
    "        '''save dict item to pickle file'''\n",
    "        \n",
    "        #df = self.load_from_pkl(filename)\n",
    "\n",
    "        #df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "\n",
    "        #df.to_pickle(filename)\n",
    "        df = pd.DataFrame(dic)\n",
    "        with open(filename, 'a') as f:\n",
    "            df.to_csv(f, header=f.tell()==0, index=None)\n",
    "    \n",
    "    def get_Dkl_i(self, values):\n",
    "        '''kl divergence for histogram'''\n",
    "        if values.any():\n",
    "            values = values + 0.00001  # make each element non-zero\n",
    "            prob = (values) / values.sum()  \n",
    "        \n",
    "            prob_uni = np.ones( len(prob) ) / len(prob)\n",
    "            return np.sum( prob_uni * np.log(prob_uni / prob) )\n",
    "        \n",
    "        else:\n",
    "            return np.NaN\n",
    "        \n",
    "    def get_FoM_i(self, dT_all, tmin=0, tmax=1.5/24, bins=50):\n",
    "        \"\"\"return FoM from array of metricValues\"\"\"\n",
    "                \n",
    "        dT_tlim = dT_all[(dT_all>tmin)&(dT_all<tmax)] \n",
    "        Nv = len(dT_tlim)\n",
    "    \n",
    "        values, bins_ = np.histogram(dT_tlim, bins=bins);\n",
    "    \n",
    "        Dkl = self.get_Dkl_i(values)\n",
    "    \n",
    "        FoM_i = Nv * np.exp(-Dkl)\n",
    "        \n",
    "        #print(self.Nrun, len(dT_all), Nv, Dkl, FoM_i)\n",
    "        return Nv, Dkl, FoM_i, dT_tlim\n",
    "      \n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        \n",
    "        # return all possible time gaps for each fields\n",
    "        \n",
    "        f0 = self.fltpair[0]\n",
    "        f1 = self.fltpair[1]\n",
    "        \n",
    "        #check input config\n",
    "        #print(f0, f1, self.tmin, self.tmax, self.mag_lim)\n",
    "            \n",
    "        # sort dataSlice\n",
    "        \n",
    "        idx0 = ( dataSlice['filter'] == f0 ) & ( dataSlice['fiveSigmaDepth'] > self.mag_lim[0])\n",
    "        idx1 = ( dataSlice['filter'] == f1 ) & ( dataSlice['fiveSigmaDepth'] > self.mag_lim[1])\n",
    "        \n",
    "        timeCol0 = dataSlice['observationStartMJD'][idx0]\n",
    "        timeCol1 = dataSlice['observationStartMJD'][idx1]\n",
    "\n",
    "        timeCol0 = timeCol0.reshape((len(timeCol0), 1))\n",
    "        timeCol1 = timeCol1.reshape((len(timeCol1), 1))\n",
    "        \n",
    "        # calculate time gaps matrix\n",
    "        diffmat = np.abs( np.subtract(timeCol0, timeCol1.T) ) \n",
    "        \n",
    "        # collect all time gaps\n",
    "        if f0==f1:\n",
    "            # get only triangle part\n",
    "            dt_tri = np.tril(diffmat, -1)\n",
    "            dT = dt_tri[dt_tri!=0]    # flatten lower triangle \n",
    "        else:\n",
    "            dT = diffmat.flatten()\n",
    "\n",
    "        Nv, Dkl, FoM_i, dT_tlim = self.get_FoM_i(dT, tmin=self.tmin, tmax=self.tmax, bins=self.bins)\n",
    "        \n",
    "        # print(self.Nrun, np.min(dataSlice['fiveSigmaDepth'][idx0]), np.min(dataSlice['fiveSigmaDepth'][idx1]),)\n",
    "        self.Nrun += 1\n",
    "        # write results to csv file\n",
    "        fieldRA = np.mean(dataSlice['fieldRA']) ,\n",
    "        fieldDec = np.mean(dataSlice['fieldDec']),\n",
    "        \n",
    "        # check whether number of visits is above threshold\n",
    "        check = len(dT_lim) >=self.Nvth[f0+f1]\n",
    "       \n",
    "        if self.save_dT:\n",
    "            dic = {'Nrun': self.Nrun, \n",
    "                'pixId': RADec2pix(nside=16, ra=fieldRA, dec=fieldDec)[0],\n",
    "                'Nv': Nv,\n",
    "                'Dkl': Dkl,\n",
    "                'FoM_i': FoM_i,\n",
    "                'dT_lim': dT_tlim,\n",
    "                'check': check\n",
    "                  }\n",
    "        else:\n",
    "            dic = {'Nrun': self.Nrun, \n",
    "                'pixId': RADec2pix(nside=16, ra=fieldRA, dec=fieldDec)[0],\n",
    "                'Nv': Nv,\n",
    "                'Dkl': Dkl,\n",
    "                'FoM_i': FoM_i,\n",
    "                'check': check\n",
    "                # 'dT_lim': dT_tlim\n",
    "                  }\n",
    "            \n",
    "        if self.filename!=None:\n",
    "            self.save_to_file(dic, filename=self.filename)\n",
    "        \n",
    "        if self.dataout:\n",
    "            # return dT\n",
    "            result = dic\n",
    "            return result\n",
    "        else:\n",
    "            # f0 = self.fltpair[0]\n",
    "            #f1 = self.fltpair[1]\n",
    "            \n",
    "            #result = np.min(dT) if len(dT)!=0 else np.inf\n",
    "            \n",
    "            return float(result) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvth = {'uu': 1770.0,\n",
    " 'ug': 50.0,\n",
    " 'ur': 47.0,\n",
    " 'ui': 6.0,\n",
    " 'uz': 0.0,\n",
    " 'uy': 0.0,\n",
    " 'gg': 3828.0,\n",
    " 'gr': 91.0,\n",
    " 'gi': 17.0,\n",
    " 'gz': 0.0,\n",
    " 'gy': 0.0,\n",
    " 'rr': 21384.0,\n",
    " 'ri': 129.0,\n",
    " 'rz': 9.0,\n",
    " 'ry': 1.0,\n",
    " 'ii': 21690.0,\n",
    " 'iz': 149.0,\n",
    " 'iy': 26.0,\n",
    " 'zz': 17310.5,\n",
    " 'zy': 123.0,\n",
    " 'yy': 18998.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21690.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0 = 'i'\n",
    "f1 = 'i'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### depthMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "\n",
    "# the depth goal \n",
    "mag_stretch = {'u':24.0, 'g':25.1, 'r':24.8, 'i':24.1, 'z':23.4, 'y':22.2 }\n",
    "\n",
    "class noveltiesDepthMetric(metrics.BaseMetric):\n",
    "    \"\"\"\n",
    "    depth \n",
    "    \n",
    "    returns\n",
    "    fiveSigmaDepth - stretch_goal\n",
    "    \n",
    "    Parameters:\n",
    "        colname: \n",
    "        fltpair: filter pair, eg ['r', 'i']\n",
    "        snr_lim: list, signal to noise ratio (fiveSigmaDepth) threshold for fltpair, default [5, 5]\n",
    "        filename: output a csv table for time gaps of each field\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, colname=['observationStartMJD', 'filter', 'fiveSigmaDepth'], \n",
    "                 fltpair=['r', 'i'], mag_lim=[18, 18], \n",
    "                 dataout=True, **kwargs):\n",
    "        self.colname = colname\n",
    "        self.fltpair = fltpair\n",
    "        self.mag_lim = mag_lim\n",
    "        self.dataout = dataout\n",
    "        \n",
    "        self.Nrun = 0   # record the how many time run run()\n",
    "       \n",
    "        if self.dataout:\n",
    "            super().__init__(col=self.colname, metricDtype='object', **kwargs)\n",
    "        else:\n",
    "            super().__init__(col=self.colname, metricDtype='float', **kwargs)\n",
    "\n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        \n",
    "        # return all possible time gaps for each fields\n",
    "        \n",
    "        f0 = self.fltpair[0]\n",
    "        f1 = self.fltpair[1]\n",
    "        \n",
    "        #check input config\n",
    "        #print(f0, f1, self.tmin, self.tmax, self.mag_lim)\n",
    "            \n",
    "        # sort dataSlice\n",
    "        \n",
    "        idx0 = ( dataSlice['filter'] == f0 ) & ( dataSlice['fiveSigmaDepth'] > self.mag_lim[0])\n",
    "        idx1 = ( dataSlice['filter'] == f1 ) & ( dataSlice['fiveSigmaDepth'] > self.mag_lim[1])\n",
    "        \n",
    "        depth0 = np.median( dataSlice['fiveSigmaDepth'][idx0] )\n",
    "        depth1 = np.median( dataSlice['fiveSigmaDepth'][idx1] )\n",
    "        \n",
    "        dic = {'f0': f0,\n",
    "               'f1': f1,\n",
    "               'depth0': depth0,\n",
    "               'depth1': depth1,\n",
    "              }\n",
    "        \n",
    "        if self.dataout:\n",
    "            # return dT\n",
    "            result = dic\n",
    "            return result\n",
    "        else:\n",
    "            # return mean of depth between two filters\n",
    "            result = np.mean([depth0, depth1])\n",
    "            return float(result) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
